# Change Log

All notable changes to the "Ollama Local Assistant" extension will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.0.0] - 2024-12-19

### Added

- Initial release of Ollama Local Assistant
- Code explanation feature - select code and get detailed AI explanations
- Code refactoring feature - automatically optimize and refactor selected code
- Code generation feature - generate code snippets based on descriptions
- Smart Q&A feature - ask questions and get professional answers
- Model management - easily switch between different local Ollama models
- Connection health check - automatically detect Ollama service status
- Stream output support - real-time response display
- Configurable settings:
  - Ollama base URL
  - Default model selection
  - Request timeout

[Unreleased]: https://github.com/zhangming9502/ollama-local-assistant/compare/v1.0.0...HEAD
[1.0.0]: https://github.com/zhangming9502/ollama-local-assistant/releases/tag/v1.0.0

