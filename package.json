{
  "name": "ollama-local-assistant",
  "displayName": "Ollama Local Assistant",
  "description": "Use local Ollama AI models in VS Code for code assistance, explanation, refactoring, and generation",
  "version": "1.0.0",
  "publisher": "zhangming9502",
  "author": "zhangming9502",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/zhangming9502/ollama-local-assistant.git"
  },
  "bugs": {
    "url": "https://github.com/zhangming9502/ollama-local-assistant/issues"
  },
  "homepage": "https://github.com/zhangming9502/ollama-local-assistant#readme",
  "keywords": [
    "ollama",
    "ai",
    "llm",
    "code-assistant",
    "code-generation",
    "code-explanation",
    "refactoring",
    "local-ai",
    "machine-learning"
  ],
  "engines": {
    "vscode": "^1.80.0"
  },
  "categories": [
    "Other",
    "Machine Learning",
    "Snippets"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "ollama.checkConnection",
        "title": "检测 Ollama 连接",
        "category": "Ollama"
      },
      {
        "command": "ollama.askQuestion",
        "title": "向 Ollama 提问",
        "category": "Ollama"
      },
      {
        "command": "ollama.explainCode",
        "title": "解释选中代码",
        "category": "Ollama"
      },
      {
        "command": "ollama.refactorCode",
        "title": "重构选中代码",
        "category": "Ollama"
      },
      {
        "command": "ollama.generateCode",
        "title": "生成代码",
        "category": "Ollama"
      },
      {
        "command": "ollama.setModel",
        "title": "设置使用的模型",
        "category": "Ollama"
      },
      {
        "command": "ollama.readFile",
        "title": "读取文件并分析",
        "category": "Ollama"
      },
      {
        "command": "ollama.writeFile",
        "title": "将 AI 输出写入文件",
        "category": "Ollama"
      },
      {
        "command": "ollama.listWorkspaceFiles",
        "title": "列出工作区文件",
        "category": "Ollama"
      },
      {
        "command": "ollama.processFile",
        "title": "处理当前文件",
        "category": "Ollama"
      }
    ],
    "configuration": {
      "title": "Ollama 本地大模型助手",
      "properties": {
        "ollama.baseUrl": {
          "type": "string",
          "default": "http://127.0.0.1:11434",
          "description": "Ollama API 的基础 URL"
        },
        "ollama.model": {
          "type": "string",
          "default": "llama3",
          "description": "默认使用的模型名称"
        },
        "ollama.timeout": {
          "type": "number",
          "default": 60000,
          "description": "API 请求超时时间（毫秒）"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "package": "vsce package",
    "publish": "vsce publish"
  },
  "devDependencies": {
    "@types/node": "^18.15.0",
    "@types/vscode": "^1.80.0",
    "typescript": "^5.0.0"
  }
}

